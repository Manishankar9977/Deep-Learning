{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols=28,28\n",
    "x_train=x_train.reshape(x_train.shape[0],rows,cols,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],rows,cols,1)\n",
    "\n",
    "input_shape=(rows,cols,1)\n",
    "\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n",
    "\n",
    "#one-hot encoding\n",
    "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Lenet (input_shape):\n",
    "    # sequentail API\n",
    "    model = tf.keras.Sequential()\n",
    "# Convolution #1. Filters as we know, is 6. Filter size is 5 x 5, tanh is the activation function. 28 x 28 is the dimension.\n",
    "    model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1,1),activation='tanh',input_shape=input_shape))\n",
    "    #model.add(tf.keras.layers.Conv2D(filters=6,kernel _size=(5,5), strides=(1, 1), activation='tanh', input_shape=input_shape))\n",
    "# SubSampling #1. Input = 28x28x6. Output = 14x14x6. SubSampling is simply Average Pooling so we use avg_pool\n",
    "    model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "# Convolution #2. Input = 14x14x6. Output = 10x10x16 conv2d\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=(5, 5), strides=(1, 1), activation='tanh'))\n",
    "# SubSampLing #2. Input = 28Ã—28x6. Output = 14x14x6. SubSampling is simply Average Pooling so we use avg_pool\n",
    "    model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "# We must flatten for the further steps to happen.\n",
    "# It is the process of converting all the resultant 2D arrays as single long continuous Linear vector\n",
    "    model.add(tf.keras. layers.Dense(units=120, activation='tanh'))\n",
    "#Fully Connected #1. Input = 5x5x16. Output = 120\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "# Flattening here. It is the process of converting all the resultant 2D arrays as single long continuous Linear\n",
    "    model.add(tf.keras.layers.Dense(units=84, activation='tanh'))\n",
    "#FulLy Connected #2. Input = 120. Output = 84\n",
    "# output Layer\n",
    "    model.add(tf.keras.layers.Dense (units=10, activation='softmax'))\n",
    "# Final, output and activation through softmax.\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.0, decay=0.0),metrics=['accuracy'])\n",
    "# Arguments passed are like the past, nothing to worry!! :)\n",
    "    return model\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = build_Lenet(input_shape)\n",
    "# We built it!\n",
    "# number of epochs\n",
    "epochs = 10\n",
    "# Can we train the model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0348 - accuracy: 0.9896\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0323 - accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0299 - accuracy: 0.9909\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0280 - accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0243 - accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0227 - accuracy: 0.9935\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0209 - accuracy: 0.9942\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0200 - accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0184 - accuracy: 0.9952\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9874\n",
      "ACCURACY: 0.9873999953269958\n"
     ]
    }
   ],
   "source": [
    "history=lenet.fit(x_train,y_train,epochs=epochs,batch_size=128,verbose=1)\n",
    "#history = lenet.fit(x_train, y_train,epochs=epochs,batch _size=128, verbose=1)\n",
    "loss, acc = lenet.evaluate(x_test, y_test)\n",
    "print ('ACCURACY:',acc)\n",
    "# Here is the most important thing to be Learnt!\n",
    "# Epochs - What is it? Simple, Epoch is once all the images are processed one time ir\n",
    "# both forward and backward to the network.\n",
    "# Epoch number can be determined by the Trail and Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (60000, 28, 28) (60000, 10)\n",
      "Training Data (10000, 28, 28) (10000, 10)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Transformation / Reshape into 28x 28 pixel\n",
    "x_train=x_train.reshape(x_train.shape[0], 28,28)\n",
    "print(\"Training Data\",x_train.shape,y_train.shape)\n",
    "\n",
    "x_test=x_test.reshape(x_test.shape[0], 28,28)\n",
    "print(\"Training Data\",x_test.shape,y_test.shape)\n",
    "#to visualize a single image at the index 8888 (6 is in the dataset)\n",
    "image_index = 8888\n",
    "plt.imshow(x_test[image_index].reshape (28, 28),cmap='Greys')\n",
    "#To predict the output using the Lenet model built\n",
    "pred = lenet.predict(x_test[image_index].reshape(1, rows, cols, 1))\n",
    "print(pred.argmax ())\n",
    "#Example 2 image @index 4444 (9 is the number in the dataset)\n",
    "#image_index = 4444\n",
    "#plt.imshow(x_test[image_index].reshape (28, 28), cmap= 'Greys')\n",
    "#pred = lenet.predict(x_test[image_index].reshape(1, rows, cols, 1))\n",
    "#print (pred.argmax ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
